# ğŸš€ Website Analysis API

A powerful REST API for intelligent website analysis and content enhancement. Extract brand information, descriptions, and enhance content using Google's Gemini AI for better readability and professionalism.

## âœ¨ Features

### ğŸ” **Smart Website Analysis**
- **Automated Content Extraction**: Extract brand names, descriptions, and metadata from any website
- **Robust Scraping Engine**: Built with Puppeteer for reliable content extraction
- **Error Handling**: Comprehensive error categorization and user-friendly messages

### ğŸ¤– **AI-Powered Enhancement**
- **Google Gemini Integration**: Leverage Google's Gemini 1.5 Flash model for content enhancement
- **Intelligent Description Improvement**: Automatically enhance website descriptions for clarity and professionalism
- **Fallback Mechanisms**: Graceful fallback to basic enhancement when AI is unavailable

### ğŸ›¡ï¸ **Enterprise-Ready Security**
- **Rate Limiting**: Configurable rate limits for different endpoints
- **Input Validation**: Comprehensive validation using express-validator
- **Error Handling**: Structured error responses with detailed logging

### ğŸ“Š **Full CRUD Operations**
- **Create**: Analyze and store new website data
- **Read**: Retrieve individual or multiple website records
- **Update**: Modify existing website information
- **Delete**: Remove website records
- **Enhance**: AI-enhance existing descriptions

## ğŸ—ï¸ Architecture

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.js                 # Application entry point
â”‚   â”œâ”€â”€ supabaseClient.js        # Database connection
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â””â”€â”€ schema.js           # Database schema validation
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”œâ”€â”€ errorHandler.js     # Global error handling
â”‚   â”‚   â”œâ”€â”€ RateLimit.js        # Rate limiting configuration
â”‚   â”‚   â””â”€â”€ validation.js       # Input validation rules
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ websiteRoutes.js    # API route definitions
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ scrapingService.js  # Web scraping logic
â”‚   â”‚   â””â”€â”€ aiEnhancementService.js # AI enhancement service
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ logger.js           # Logging utility
â””â”€â”€ logs/                       # Application logs
    â”œâ”€â”€ info.log
    â””â”€â”€ error.log
```

## ğŸš€ Quick Start

### Prerequisites

- **Node.js** 20.x or higher
- **Supabase** account and project
- **Google AI Studio** API key ([Get one here](https://makersuite.google.com/app/apikey))

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/SubhPanda04/Nurdd.git
   cd Nurdd
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Environment Configuration**
   ```bash
   cp .env.example .env
   ```
   
   Configure your `.env` file:
   ```env
   SUPABASE_URL=your_supabase_url
   SUPABASE_KEY=your_supabase_anon_key
   GEMINI_API_KEY=your_gemini_api_key
   PORT=3000
   ```

4. **Database Setup**
   
   Create the following table in your Supabase SQL editor:
   ```sql
   CREATE TABLE website_analysis (
     id SERIAL PRIMARY KEY,
     url VARCHAR(500) NOT NULL,
     brand_name VARCHAR(255),
     description TEXT,
     raw_description TEXT,
     enhanced BOOLEAN DEFAULT FALSE,
     created_at TIMESTAMP DEFAULT NOW(),
     updated_at TIMESTAMP DEFAULT NOW()
   );
   ```

5. **Start the server**
   ```bash
   # Development mode
   npm run dev
   
   # Production mode
   npm start
   ```

## ğŸ“– API Documentation

### Base URL
```
http://localhost:3000/api/websites
```

### ğŸ” **Analyze Website**
```http
POST /analyze
```

**Request Body:**
```json
{
  "url": "https://example.com",
  "enhanceDescription": true
}
```

**Response:**
```json
{
  "message": "Website analyzed successfully",
  "data": {
    "id": 1,
    "url": "https://example.com",
    "brand_name": "Example Corp",
    "description": "Enhanced professional description...",
    "raw_description": "Original extracted description...",
    "enhanced": true,
    "created_at": "2025-08-17T10:30:00Z",
    "aiStats": {
      "enabled": true,
      "model": "gemini-1.5-flash",
      "fallbackMode": false
    }
  }
}
```

### ğŸ“‹ **Get All Records**
```http
GET /
```

**Response:**
```json
{
  "message": "Website records retrieved successfully",
  "count": 10,
  "data": [...]
}
```

### ğŸ” **Get Single Record**
```http
GET /:id
```

### âœï¸ **Update Record**
```http
PUT /:id
```

**Request Body:**
```json
{
  "brand_name": "Updated Brand Name",
  "description": "Updated description..."
}
```

### ğŸ—‘ï¸ **Delete Record**
```http
DELETE /:id
```

### ğŸ¤– **Enhance Existing Description**
```http
POST /:id/enhance
```

### ğŸ“Š **AI Service Status**
```http
GET /ai/status
```

**Response:**
```json
{
  "message": "AI enhancement status",
  "enabled": true,
  "model": "gemini-1.5-flash",
  "fallbackMode": false,
  "features": {
    "enhanceDescription": true,
    "supportedLanguages": ["en"],
    "maxDescriptionLength": 1000
  }
}
```

## ğŸ› ï¸ Technology Stack

| Technology | Purpose | Version |
|------------|---------|---------|
| **Node.js** | Runtime Environment | 20.x |
| **Express.js** | Web Framework | 4.18 |
| **Puppeteer** | Web Scraping | 24.16 |
| **Cheerio** | HTML Parsing | 1.1 |
| **Supabase** | Database & Backend | 2.55 |
| **Google Gemini** | AI Enhancement | 1.5-flash |
| **Express Validator** | Input Validation | 7.2 |
| **Express Rate Limit** | Rate Limiting | 8.0 |

## ğŸ”§ Configuration

### Rate Limiting
- **Analysis Endpoint**: 20 requests per 10 minutes
- **General Endpoints**: 100 requests per 15 minutes


## ğŸ” Security Features

- **Input Validation**: All inputs validated using express-validator
- **Rate Limiting**: Prevent API abuse with configurable limits
- **Error Sanitization**: Sensitive information filtered from error responses
- **CORS Enabled**: Cross-origin requests properly configured
- **Request Timeout**: Prevents hanging requests

<div align="center">
  <strong>Made with â¤ï¸ for intelligent web analysis</strong>
</div>
